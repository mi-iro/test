import argparse
import os
import sys
import torch
import asyncio
import json
import yaml  # éœ€è¦å®‰è£… pyyaml: pip install pyyaml

# ç¡®ä¿é¡¹ç›®æ ¹ç›®å½•åœ¨ sys.path ä¸­ï¼Œä»¥ä¾¿å¯¼å…¥ src æ¨¡å—
sys.path.append(os.path.abspath(os.path.dirname(__file__)))

from src.agents.AgenticRAGAgent import AgenticRAGAgent
from src.agents.ElementExtractor import ElementExtractor
from src.agents.utils import ImageZoomOCRTool
from src.loaders.MMLongLoader import MMLongLoader
from src.loaders.FinRAGLoader import FinRAGLoader
from src.utils.llm_helper import create_llm_caller

try:
    from scripts.qwen3_vl_embedding import Qwen3VLEmbedder
    from scripts.qwen3_vl_reranker import Qwen3VLReranker
except ImportError:
    print("Warning: Qwen3 VL scripts not found.")

def get_parser():
    """å®šä¹‰å‚æ•°è§£æå™¨ï¼Œä½†ä¸ç«‹å³è§£æ"""
    parser = argparse.ArgumentParser(description="Run AgenticRAGAgent benchmark evaluation.")

    # ------------------ æ–°å¢é…ç½® ------------------
    # é…ç½®æ–‡ä»¶è·¯å¾„
    parser.add_argument("--config", type=str, default=None, help="Path to YAML configuration file.")
    # æ¨ç†æ¨¡å¼å¼€å…³ (åªè·‘æ¨ç†ï¼Œä¸è·‘è¯„ä¼°)
    parser.add_argument("--infer_only", action="store_true", help="If set, skip the evaluation step and only run inference.")
    # ---------------------------------------------

    # åŸºç¡€é…ç½®
    parser.add_argument("--benchmark", type=str, default="mmlong", choices=["mmlong", "finrag"], help="Target benchmark to run.")
    parser.add_argument("--data_root", type=str, default="/mnt/shared-storage-user/mineru3-share/wangzhengren/PageElement/MMLongBench-Doc", help="Path to the dataset root directory.")
    parser.add_argument("--output_dir", type=str, default="./results_mmlong", help="Directory to save results and cache.")
    
    # LLM é…ç½® (Main Agent ä½¿ç”¨)
    parser.add_argument("--model_name", type=str, default="qwen3-max", help="LLM model name (e.g., qwen3-max).")
    parser.add_argument("--base_url", type=str, default="http://localhost:3888/v1", help="LLM API Base URL.")
    parser.add_argument("--api_key", type=str, default="sk-6TGzZJkJ5HfZKwnrS1A1pMb1lH5D7EDfSVC6USq24aN2JaaR", help="LLM API Key.")
    
    # Agent é…ç½®
    parser.add_argument("--max_rounds", type=int, default=5, help="Maximum thinking rounds for AgenticRAGAgent.")
    parser.add_argument("--limit", type=int, default=5, help="Limit the number of samples for testing (e.g., 10).")

    # æ¨¡å‹è·¯å¾„é…ç½® (æ ¹æ® Benchmark éœ€æ±‚)
    parser.add_argument("--embedding_model", type=str, default="/mnt/shared-storage-user/mineru3-share/wangzhengren/JIT-RAG/assets/Qwen/Qwen3-VL-Embedding-8B", help="Path to Qwen3-VL-Embedding model (Required for FinRAG).")
    parser.add_argument("--reranker_model", type=str, default="/mnt/shared-storage-user/mineru3-share/wangzhengren/JIT-RAG/assets/Qwen/Qwen3-VL-Reranker-8B", help="Path to Qwen3-VL-Reranker model.")
    
    # MinerU / OCR é…ç½®
    parser.add_argument("--mineru_server_url", type=str, default="http://10.102.250.36:8000/", help="MinerU API Server URL.")
    parser.add_argument("--mineru_model_path", type=str, default="/root/checkpoints/MinerU2.5-2509-1.2B/", help="MinerU Model Path.")
    
    # ElementExtractor é…ç½®
    parser.add_argument("--extractor_model_name", type=str, default="MinerU-Agent-CK300", help="LLM model name (e.g., qwen3-max).")
    parser.add_argument("--extractor_base_url", type=str, default="http://localhost:8001/v1", help="LLM API Base URL.")
    parser.add_argument("--extractor_api_key", type=str, default="sk-123456", help="LLM API Key.")

    # FinRAG ç‰¹æœ‰é…ç½®
    parser.add_argument("--finrag_lang", type=str, default="ch", choices=["ch", "en", "bbox"], help="Language/subset for FinRAG.")
    parser.add_argument("--force_rebuild_index", action="store_true", help="Force rebuild vector index for FinRAG.")

    return parser

def parse_args_with_config():
    """
    è§£æå‚æ•°ï¼Œæ”¯æŒä»YAMLæ–‡ä»¶åŠ è½½é…ç½®ã€‚
    ä¼˜å…ˆçº§: å‘½ä»¤è¡Œå‚æ•° > YAMLæ–‡ä»¶ > é»˜è®¤å€¼
    """
    parser = get_parser()
    
    # 1. é¢„è§£æï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ config å‚æ•°
    temp_args, _ = parser.parse_known_args()
    
    # 2. å¦‚æœæŒ‡å®šäº† config æ–‡ä»¶ï¼ŒåŠ è½½å¹¶æ›´æ–° defaults
    if temp_args.config and os.path.exists(temp_args.config):
        print(f"ğŸ“„ Loading configuration from {temp_args.config}...")
        with open(temp_args.config, 'r', encoding='utf-8') as f:
            config_data = yaml.safe_load(f)
            if config_data:
                parser.set_defaults(**config_data)
    elif temp_args.config:
        print(f"âš ï¸ Warning: Config file {temp_args.config} not found. Using defaults.")

    # 3. æœ€ç»ˆè§£æ (ç¡®ä¿å‘½ä»¤è¡Œå‚æ•°è¦†ç›– YAML é…ç½®)
    args = parser.parse_args()
    return args

def main():
    # ä½¿ç”¨æ”¯æŒ Config çš„è§£æé€»è¾‘
    args = parse_args_with_config()

    # 1. ç›®å½•å‡†å¤‡
    os.makedirs(args.output_dir, exist_ok=True)
    workspace_dir = os.path.join(args.output_dir, "workspace")
    cache_dir = os.path.join(args.output_dir, "cache")
    os.makedirs(workspace_dir, exist_ok=True)
    os.makedirs(cache_dir, exist_ok=True)

    # ------------------ ä¿®æ”¹ï¼šä¿å­˜ä¸º YAML ------------------
    config_path = os.path.join(args.output_dir, "config.yaml")
    with open(config_path, "w", encoding="utf-8") as f:
        # default_flow_style=False ç¡®ä¿è¾“å‡ºä¸ºå—çŠ¶æ ¼å¼ï¼Œæ›´æ˜“è¯»
        yaml.dump(vars(args), f, default_flow_style=False, allow_unicode=True)
    print(f"ğŸ“ Configuration saved to: {config_path}")
    # -----------------------------------------------------

    print(f"ğŸš€ Starting Benchmark: {args.benchmark.upper()}")
    print(f"ğŸ“‚ Data Root: {args.data_root}")
    print(f"ğŸ’¾ Output Dir: {args.output_dir}")
    print(f"ğŸ”„ Infer Only Mode: {args.infer_only}")

    # 2. åˆå§‹åŒ–åº•å±‚å·¥å…·ä¸æå–å™¨ (ElementExtractor)
    print("ğŸ› ï¸ Initializing Tools and Extractor...")
    tool = ImageZoomOCRTool(
        work_dir=os.path.join(workspace_dir, "crops"),
        mineru_server_url=args.mineru_server_url,
        mineru_model_path=args.mineru_model_path
    )
    
    extractor = ElementExtractor(
        base_url=args.extractor_base_url,
        api_key=args.extractor_api_key,
        model_name=args.extractor_model_name,
        tool=tool
    )

    loader = None

    # 3. åˆå§‹åŒ– DataLoader
    if args.benchmark == "mmlong":
        print("ğŸ“¥ Loading MMLongLoader...")
        loader = MMLongLoader(
            data_root=args.data_root, 
            extractor=extractor,
            reranker_model_path=args.reranker_model
        )
        loader.load_data()

    elif args.benchmark == "finrag":
        print("ğŸ“¥ Loading FinRAGLoader...")
        if not args.embedding_model or not args.reranker_model:
            raise ValueError("FinRAG benchmark requires --embedding_model and --reranker_model.")
        
        print("   Loading Embedding Model (this may take time)...")
        embedder = Qwen3VLEmbedder(model_name_or_path=args.embedding_model, torch_dtype=torch.float16)
        print("   Loading Reranker Model...")
        reranker = Qwen3VLReranker(model_name_or_path=args.reranker_model, torch_dtype=torch.float16)

        loader = FinRAGLoader(
            data_root=args.data_root,
            lang=args.finrag_lang,
            embedding_model=embedder,
            rerank_model=reranker,
            extractor=extractor
        )
        loader.load_data()
        
        loader.build_page_vector_pool(batch_size=4, force_rebuild=args.force_rebuild_index)

    # è®¾ç½®ç”¨äºè¯„ä¼°çš„ LLM Helper
    loader.llm_caller = create_llm_caller()

    # 4. æˆªå–æµ‹è¯•æ ·æœ¬ (å¦‚æœè®¾ç½®äº† limit)
    if args.limit and args.limit > 0:
        print(f"âš ï¸ Limiting samples to {args.limit} for testing.")
        loader.samples = loader.samples[:args.limit]

    print(f"ğŸ“Š Total Samples to Process: {len(loader.samples)}")

    # 5. åˆå§‹åŒ– Agentic RAG Agent
    agent = AgenticRAGAgent(
        loader=loader,
        base_url=args.base_url,
        api_key=args.api_key,
        model_name=args.model_name,
        max_rounds=args.max_rounds,
        cache_dir=cache_dir
    )

    # 6. æ‰§è¡Œå¤„ç†å¾ªç¯
    print("\nâš¡ Starting Processing Loop...")
    for i, sample in enumerate(loader.samples):
        print(f"[{i+1}/{len(loader.samples)}] Processing Sample QID: {sample.qid}")
        agent.process_sample(sample)

    # 7. ä¿å­˜ç»“æœ
    excel_path = os.path.join(args.output_dir, f"{args.benchmark}_results.xlsx")
    json_path = os.path.join(args.output_dir, f"{args.benchmark}_results.json")
    agent.save_results(excel_path=excel_path, json_path=json_path)

    # 8. æ‰§è¡Œè¯„ä¼° (æ ¹æ® infer_only å¼€å…³å†³å®šæ˜¯å¦è·³è¿‡)
    # ------------------ ä¿®æ”¹ï¼šInfer Only é€»è¾‘ ------------------
    if args.infer_only:
        print("\nâ­ï¸  Skipping Evaluation (Infer Only Mode Enabled).")
        print(f"âœ… Inference complete. Results saved to {args.output_dir}")
    else:
        print("\nğŸ“ˆ Starting Evaluation...")
        try:
            metrics = loader.evaluate()
            # ä¿å­˜è¯„ä¼°æŒ‡æ ‡
            metrics_path = os.path.join(args.output_dir, "evaluation_metrics.json")
            with open(metrics_path, "w", encoding="utf-8") as f:
                json.dump(metrics, f, indent=2)
            print(f"âœ… Evaluation complete. Metrics saved to {metrics_path}")
        except Exception as e:
            print(f"âŒ Evaluation failed: {e}")
    # ---------------------------------------------------------

if __name__ == "__main__":
    main()